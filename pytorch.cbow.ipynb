{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 10\n",
    "CONTEXT_SIZE = 2 # on either side of the center word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_idx = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(d):\n",
    "    return dict([ (v, k) for k, v in d.items() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_words = invert_dict(words_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_word = [([raw_text[i-2], raw_text[i-1], raw_text[i+1], raw_text[i+2]], raw_text[i]) \n",
    "                for i in range(2, len(raw_text)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_numbers(io, mapping):\n",
    "    i_ret = []\n",
    "    o_ret = None\n",
    "    \n",
    "    for word in io[0]:\n",
    "        i_ret.append(words_to_idx[word])\n",
    "    o_ret = words_to_idx[io[1]]\n",
    "    \n",
    "    return (i_ret, o_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear1 = nn.Linear(embed_dim,128)\n",
    "        self.linear2 = nn.Linear(128,256)\n",
    "        self.linear3 = nn.Linear(256, vocab_size)\n",
    "        \n",
    "    def forward(self, the_input):\n",
    "        out = self.embed(the_input).sum(dim=0).view((1, -1))\n",
    "        out = F.relu(self.linear1(out))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = self.linear3(out)\n",
    "        log_prob = F.log_softmax(out, dim=1)\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(vocab_len, EMBED_DIM).cuda()\n",
    "loss_fn = nn.NLLLoss().cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2000):\n",
    "    \n",
    "    for cw in context_word:\n",
    "        c, w = words_to_numbers(cw, words_to_idx)\n",
    "        cvar = autograd.Variable(torch.cuda.LongTensor(c), requires_grad=False)\n",
    "        wvar = autograd.Variable(torch.cuda.LongTensor([w]), requires_grad=False)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        log_prob = model(cvar)\n",
    "        loss = loss_fn(log_prob, wvar)\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model.eval()\n",
    "for context, target in context_word:\n",
    "        c, w = words_to_numbers(cw, words_to_idx)\n",
    "        cvar = autograd.Variable(torch.LongTensor(c))\n",
    "        wvar = autograd.Variable(torch.LongTensor([w]))\n",
    "        lp = model(cvar)\n",
    "        \n",
    "        # val, idx= torch.max(lp, -1)\n",
    "        # print(context, target, words_to_idx[target],idx.data[0])\n",
    "        \n",
    "        n = lp.data.numpy()[0]\n",
    "        print(n)\n",
    "        print(context, target, words_to_idx[target], np.argmax(n))\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'to', 'study'] about As\n",
      "['are', 'about', 'study', 'the'] to abstract\n",
      "['about', 'to', 'the', 'idea'] study the\n",
      "['to', 'study', 'idea', 'of'] the abstract\n",
      "['study', 'the', 'of', 'a'] idea abstract\n",
      "['the', 'idea', 'a', 'computational'] of abstract\n",
      "['idea', 'of', 'computational', 'process.'] a abstract\n",
      "['of', 'a', 'process.', 'Computational'] computational abstract\n",
      "['a', 'computational', 'Computational', 'processes'] process. directed\n",
      "['computational', 'process.', 'processes', 'are'] Computational is\n",
      "['process.', 'Computational', 'are', 'abstract'] processes directed\n",
      "['Computational', 'processes', 'abstract', 'beings'] are directed\n",
      "['processes', 'are', 'beings', 'that'] abstract the\n",
      "['are', 'abstract', 'that', 'inhabit'] beings things\n",
      "['abstract', 'beings', 'inhabit', 'computers.'] that of\n",
      "['beings', 'that', 'computers.', 'As'] inhabit directed\n",
      "['that', 'inhabit', 'As', 'they'] computers. directed\n",
      "['inhabit', 'computers.', 'they', 'evolve,'] As directed\n",
      "['computers.', 'As', 'evolve,', 'processes'] they the\n",
      "['As', 'they', 'processes', 'manipulate'] evolve, the\n",
      "['they', 'evolve,', 'manipulate', 'other'] processes the\n",
      "['evolve,', 'processes', 'other', 'abstract'] manipulate directed\n",
      "['processes', 'manipulate', 'abstract', 'things'] other study\n",
      "['manipulate', 'other', 'things', 'called'] abstract process.\n",
      "['other', 'abstract', 'called', 'data.'] things process.\n",
      "['abstract', 'things', 'data.', 'The'] called study\n",
      "['things', 'called', 'The', 'evolution'] data. process.\n",
      "['called', 'data.', 'evolution', 'of'] The abstract\n",
      "['data.', 'The', 'of', 'a'] evolution abstract\n",
      "['The', 'evolution', 'a', 'process'] of create\n",
      "['evolution', 'of', 'process', 'is'] a inhabit\n",
      "['of', 'a', 'is', 'directed'] process abstract\n",
      "['a', 'process', 'directed', 'by'] is process.\n",
      "['process', 'is', 'by', 'a'] directed directed\n",
      "['is', 'directed', 'a', 'pattern'] by the\n",
      "['directed', 'by', 'pattern', 'of'] a abstract\n",
      "['by', 'a', 'of', 'rules'] pattern the\n",
      "['a', 'pattern', 'rules', 'called'] of process.\n",
      "['pattern', 'of', 'called', 'a'] rules abstract\n",
      "['of', 'rules', 'a', 'program.'] called abstract\n",
      "['rules', 'called', 'program.', 'People'] a process.\n",
      "['called', 'a', 'People', 'create'] program. directed\n",
      "['a', 'program.', 'create', 'programs'] People directed\n",
      "['program.', 'People', 'programs', 'to'] create directed\n",
      "['People', 'create', 'to', 'direct'] programs abstract\n",
      "['create', 'programs', 'direct', 'processes.'] to abstract\n",
      "['programs', 'to', 'processes.', 'In'] direct directed\n",
      "['to', 'direct', 'In', 'effect,'] processes. the\n",
      "['direct', 'processes.', 'effect,', 'we'] In inhabit\n",
      "['processes.', 'In', 'we', 'conjure'] effect, abstract\n",
      "['In', 'effect,', 'conjure', 'the'] we is\n",
      "['effect,', 'we', 'the', 'spirits'] conjure process.\n",
      "['we', 'conjure', 'spirits', 'of'] the study\n",
      "['conjure', 'the', 'of', 'the'] spirits abstract\n",
      "['the', 'spirits', 'the', 'computer'] of abstract\n",
      "['spirits', 'of', 'computer', 'with'] the abstract\n",
      "['of', 'the', 'with', 'our'] computer abstract\n",
      "['the', 'computer', 'our', 'spells.'] with idea\n"
     ]
    }
   ],
   "source": [
    "for context, target in context_word:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in variables)\n",
    "        context_idxs = [words_to_idx[w] for w in context]\n",
    "        context_var = autograd.Variable(torch.cuda.LongTensor(context_idxs))\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_var)\n",
    "        _,idx= torch.min(log_probs,-1)\n",
    "        print (context,target, idx_to_words[idx.data[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
